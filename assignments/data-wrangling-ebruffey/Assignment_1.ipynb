{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview \n",
    "\n",
    "- The goal of this assignment is to practice some important data wrangling functionality commonly required in real-world projects.\n",
    "\n",
    "- Here we will use two datasets:\n",
    "  - IRS Statistics of Income (SOI) dataset\n",
    "  - The Medicaid Data per State  \n",
    "\n",
    "\n",
    "- The final product here is a table with medication cost per Medicaid enrollee per state. This dataset will allow us to answer such questions as:\n",
    "  - Which medications account for the bulk of a state's spending   \n",
    "  - Which drugs are prescribed much more in one state compared to the other states.\n",
    "etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instructions on answering the questions\n",
    "\n",
    "- Some of the questions below require that you only use methods or properties of a `DataFrame` or a `Series`. Therefore, any solution that uses a function that is not a method or property of `DataFrame`s or `Series` will not be accepted, even when the solution yields an appropriate answer to the question.\n",
    "\n",
    "- For instance, if you are asked to find the number of entries in the DataFrame `tax_data ` using only the DataFrame's methods or properties, then `len(tax_data)` is not an acceptable solution since `len()` is not a `tax_data` method. The statements below are both correct answers:\n",
    "\n",
    "  - `info()` is a method `tax_data`\n",
    "  \n",
    "```python\n",
    "   \n",
    "    tax_data.info()\n",
    "```\n",
    "\n",
    "  or\n",
    "\n",
    "  - `shape` is a property of `tax_data`\n",
    "\n",
    "\n",
    "```python\n",
    "tax_data.shape\n",
    "```\n",
    "\n",
    "- Similarly, if you are asked to find to count the number of unique entries in the `STATEFIPS` column of the `tax_data` DataFrame, then solutions using set() or len() are not acceptable for the following reasons:\n",
    "\n",
    "- The solution below uses `set()` and `len()`, which are not `tax_data` methods\n",
    "\n",
    "```python\n",
    "len(set(tax_data[\"STATEFIPS\"]))\n",
    "```\n",
    "\n",
    "- The solution below uses `unique()`, which is a  `tax_data` method, but then counts the number of uniques entries using `len()` which is not `tax_data` method\n",
    "\n",
    "```python\n",
    "len(tax_data[\"STATEFIPS\"].unique())\n",
    "```\n",
    "\n",
    "\n",
    "- The statement below is an acceptable solution since it uses `nunique()` which is a method of the `Series` generated by indexing on a column of `tax_data` (`tax_data['STATEFIPS'])\n",
    "\n",
    "```python\n",
    "tax_data['STATEFIPS'].nunique()\n",
    "```\n",
    "\n",
    "\n",
    "- Chaining methods and properties is encouraged if it does not cause ambiguity \n",
    "\n",
    "- For instance, to identify whether a value is part of the index, write the following:\n",
    "\n",
    "```python\n",
    "tax_data.index.contains(99999)\n",
    "```\n",
    "\n",
    "- Rather than:\n",
    "\n",
    "```python\n",
    "9999 in tax_data.index\n",
    "```\n",
    "\n",
    "- You can only import `pandas` and `numpy`\n",
    "\n",
    "- If you are not explicitely asked to only use methods or properties of a `DataFrame` or a `Series`, then any solution that does not rely on external products will be accepted.\n",
    "\n",
    "- __Important__: Provide the exact statement(s) used to answer each question\n",
    "\n",
    "- Unless otherwise specified, each cell can contain multiple lines of code\n",
    "\n",
    "* Finally, note that not all the functions necessary for answering the questions below were covered in class. As such, I suggest you use `.SHIFT+TAB` on objects liberally to see which methods and properties are available on objects. If you are unsure what a method does, use `SHIFT+TAB` twice to invoke the `docstring`, or documentation for that function. This is not only a good way to see which functionality can be used to answer the questions below but also a great way to familiarize yourself with the plethora or functionality available through the `pandas` package.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Load the IRS Statistics of Income (SOI) dataset (tax_data.csv) into a `DataFrame` called `tax_data`. The file is `tax_data.csv` is located in the `data` directory of the assignment folder.\n",
    "\n",
    "* This dataset was preprocessed but the original one was obtained at the following URL:\n",
    "\n",
    "        https://www.irs.gov/pub/irs-soi/15zpallagi.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "tax_data = pd.read_csv('~/code/python/ICS434/assignments/one/data-wrangling-ebruffey/data/tax_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a `tax_data` method or property to display the first eight (8) rows of the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   STATEFIPS STATE  ZIPCODE  AGI_STUB        N1     MARS1     MARS2     MARS4  \\\n0        1.0    AL      0.0       1.0  836320.0  481570.0  109790.0  233260.0   \n1        1.0    AL      0.0       2.0  494830.0  206630.0  146250.0  129390.0   \n2        1.0    AL      0.0       3.0  261250.0   80720.0  139280.0   36130.0   \n3        1.0    AL      0.0       4.0  166690.0   28510.0  124650.0   10630.0   \n4        1.0    AL      0.0       5.0  212660.0   19520.0  184320.0    4830.0   \n5        1.0    AL      0.0       6.0   55360.0    2950.0   49260.0     350.0   \n6        1.0    AL  35004.0       1.0    1490.0     970.0     230.0     280.0   \n7        1.0    AL  35004.0       2.0    1350.0     630.0     360.0     300.0   \n\n       PREP         N2  ...    N10300     A10300   N85530   A85530   N85300  \\\n0  455560.0  1356760.0  ...  373410.0   328469.0      0.0      0.0      0.0   \n1  275920.0  1010990.0  ...  395880.0   965011.0      0.0      0.0      0.0   \n2  155100.0   583910.0  ...  251490.0  1333418.0      0.0      0.0      0.0   \n3   99950.0   423990.0  ...  165320.0  1414283.0      0.0      0.0      0.0   \n4  126860.0   589490.0  ...  212000.0  3820152.0    420.0    168.0     60.0   \n5   41410.0   160530.0  ...   55300.0  6027793.0  22090.0  39519.0  27550.0   \n6     700.0     2160.0  ...     690.0      610.0      0.0      0.0      0.0   \n7     610.0     2540.0  ...    1140.0     3019.0      0.0      0.0      0.0   \n\n    A85300   N11901    A11901    N11902     A11902  \n0      0.0  61920.0   48150.0  732670.0  1933120.0  \n1      0.0  73720.0  107304.0  415410.0  1187403.0  \n2      0.0  64200.0  139598.0  193030.0   536699.0  \n3      0.0  45460.0  128823.0  116440.0   377177.0  \n4     31.0  83330.0  421004.0  121570.0   483682.0  \n5  95112.0  28590.0  791573.0   15960.0   250289.0  \n6      0.0    120.0      94.0    1290.0     2792.0  \n7      0.0    210.0     301.0    1130.0     2935.0  \n\n[8 rows x 91 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATEFIPS</th>\n      <th>STATE</th>\n      <th>ZIPCODE</th>\n      <th>AGI_STUB</th>\n      <th>N1</th>\n      <th>MARS1</th>\n      <th>MARS2</th>\n      <th>MARS4</th>\n      <th>PREP</th>\n      <th>N2</th>\n      <th>...</th>\n      <th>N10300</th>\n      <th>A10300</th>\n      <th>N85530</th>\n      <th>A85530</th>\n      <th>N85300</th>\n      <th>A85300</th>\n      <th>N11901</th>\n      <th>A11901</th>\n      <th>N11902</th>\n      <th>A11902</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>836320.0</td>\n      <td>481570.0</td>\n      <td>109790.0</td>\n      <td>233260.0</td>\n      <td>455560.0</td>\n      <td>1356760.0</td>\n      <td>...</td>\n      <td>373410.0</td>\n      <td>328469.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>61920.0</td>\n      <td>48150.0</td>\n      <td>732670.0</td>\n      <td>1933120.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>494830.0</td>\n      <td>206630.0</td>\n      <td>146250.0</td>\n      <td>129390.0</td>\n      <td>275920.0</td>\n      <td>1010990.0</td>\n      <td>...</td>\n      <td>395880.0</td>\n      <td>965011.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>73720.0</td>\n      <td>107304.0</td>\n      <td>415410.0</td>\n      <td>1187403.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>261250.0</td>\n      <td>80720.0</td>\n      <td>139280.0</td>\n      <td>36130.0</td>\n      <td>155100.0</td>\n      <td>583910.0</td>\n      <td>...</td>\n      <td>251490.0</td>\n      <td>1333418.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>64200.0</td>\n      <td>139598.0</td>\n      <td>193030.0</td>\n      <td>536699.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>166690.0</td>\n      <td>28510.0</td>\n      <td>124650.0</td>\n      <td>10630.0</td>\n      <td>99950.0</td>\n      <td>423990.0</td>\n      <td>...</td>\n      <td>165320.0</td>\n      <td>1414283.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>45460.0</td>\n      <td>128823.0</td>\n      <td>116440.0</td>\n      <td>377177.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>212660.0</td>\n      <td>19520.0</td>\n      <td>184320.0</td>\n      <td>4830.0</td>\n      <td>126860.0</td>\n      <td>589490.0</td>\n      <td>...</td>\n      <td>212000.0</td>\n      <td>3820152.0</td>\n      <td>420.0</td>\n      <td>168.0</td>\n      <td>60.0</td>\n      <td>31.0</td>\n      <td>83330.0</td>\n      <td>421004.0</td>\n      <td>121570.0</td>\n      <td>483682.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>55360.0</td>\n      <td>2950.0</td>\n      <td>49260.0</td>\n      <td>350.0</td>\n      <td>41410.0</td>\n      <td>160530.0</td>\n      <td>...</td>\n      <td>55300.0</td>\n      <td>6027793.0</td>\n      <td>22090.0</td>\n      <td>39519.0</td>\n      <td>27550.0</td>\n      <td>95112.0</td>\n      <td>28590.0</td>\n      <td>791573.0</td>\n      <td>15960.0</td>\n      <td>250289.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>35004.0</td>\n      <td>1.0</td>\n      <td>1490.0</td>\n      <td>970.0</td>\n      <td>230.0</td>\n      <td>280.0</td>\n      <td>700.0</td>\n      <td>2160.0</td>\n      <td>...</td>\n      <td>690.0</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>94.0</td>\n      <td>1290.0</td>\n      <td>2792.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>35004.0</td>\n      <td>2.0</td>\n      <td>1350.0</td>\n      <td>630.0</td>\n      <td>360.0</td>\n      <td>300.0</td>\n      <td>610.0</td>\n      <td>2540.0</td>\n      <td>...</td>\n      <td>1140.0</td>\n      <td>3019.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>210.0</td>\n      <td>301.0</td>\n      <td>1130.0</td>\n      <td>2935.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 91 columns</p>\n</div>"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "tax_data.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Modify `tax_data` to uppercase all the header name. \n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  * Do not hardcode the operation by uppercasing the columns yourself\n",
    "  *  You can `tax_data.columns`, which returns a `Series` of the column names.\n",
    "  \n",
    "* The resulting column name should look as follows:\n",
    "\n",
    "\n",
    "```\n",
    "STATEFIPS    STATE    ZIPCODE    AGI_STUB    N1    MARS1    MARS2    MARS4    PREP    N2    ...    \n",
    "```\n",
    "\n",
    "This operation is useful for standardizing column names and avoid guessing whether the column header was in upper case, lower case or a mix of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tax_data.columns = tax_data.columns.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total number of entries (also called observations) in `tax_data`?\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(166698, 91)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "tax_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `STATEFIPS` is header title of the first column of the `tax_data` `DataFrame`, what is the title of the 32nd column\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties and should use a single python expression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'N00900'"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "tax_data.columns[31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If `STATEFIPS` is the the first column, what is the index of the column name `N10300`?\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "81"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "tax_data.columns.get_loc('N10300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the count of unique zip codes in each state using descending order.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "\n",
    "- The result should look like the following ( '...' represents remaining data that is not shown)\n",
    "```python\n",
    "\n",
    "        ZIPCODE\n",
    "STATE\t\n",
    "TX\t     9714\n",
    "NY\t     9238\n",
    "CA\t     8908\n",
    "PA\t     8208\n",
    "IL\t     7386\n",
    "...\n",
    "```\n",
    "\n",
    "* The above indicates that there are 9,714 unique zipcodes in TX, 9,238 in NY, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "states_zips = tax_data.groupby('STATE')['ZIPCODE'].nunique()\n",
    "states_zips = states_zips.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify the position of HI in the list of zip code counts per state (questions directly above)\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   STATE  ZIPCODE\n11    HI       60",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATE</th>\n      <th>ZIPCODE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>HI</td>\n      <td>60</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "states_zips.loc[states_zips['STATE'] == 'HI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Removing Ambiguous Zip Codes\n",
    "\n",
    "- Count the number of entries where ZIPCODE is 0, assign your results to a variable named  `nb_invalid_zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n"
     ]
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "nb_invalid_zip = tax_data['ZIPCODE'].value_counts()[0.0].tolist()\n",
    "#type(nb_invalid_zip)\n",
    "print(nb_invalid_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to make sure that `nb_invalid_zip` is an integer (`int`)\n",
    "  * Note that `assert` will only print an error if `type(nb_invalid_zip)` is not of type `int`\n",
    "  \n",
    "* If `nb_invalid_zip` then change your answer above so that the value returned is effectively a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(type(nb_invalid_zip) == int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove from `tax_data` all the lines where the zip code is `0` and save resulting `DataFrame` to a variable named `tax_data_valid_zip`\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "(166392, 91)"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tax_data_valid_zip = tax_data[tax_data['ZIPCODE'] != 0.0]\n",
    "tax_data_valid_zip.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected\n",
    "\n",
    "  * The assertion below is testing that the number of lines with \"zip code equal to  0\" + number of lines in `tax_data_valid_zip` is equal to the number of lines in the original `DataFrame` `tax_data`\n",
    "  \n",
    "  * The assertion below will fail (and print an error message) if the results do not match. If that is the case, please review your code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip.shape[0] + nb_invalid_zip) == tax_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying and Removing Lines with Missing Values\n",
    "\n",
    "* How many lines contain at least one missing value `NaN` in the `tax_data_valid_zip` `DataFrame`?\n",
    "  * Your answer can only use `DataFrame` methods and properties\n",
    "* Assing the count of `NaN` into a variable called nb_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "139"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "nb_missing_values = tax_data_valid_zip.isnull().any(axis=1).sum()\n",
    "#tax_data_valid_zip.info()\n",
    "nb_missing_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new `DataFrame` containing all the lines from `tax_data_valid_zip`, except lines containing missing values\n",
    "\n",
    "* Call the new `DataFrame` `tax_data_valid_zip_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(166253, 91)"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "tax_data_valid_zip_cleaned = tax_data_valid_zip.dropna(axis=0)\n",
    "tax_data_valid_zip_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected. The assertion below is testing that:  \n",
    "`nb_missing_values` + number of lines in `tax_data_valid_zip_cleaned` is equal to the number of lines in `tax_data_valid_zip`\n",
    "  \n",
    "* Note that assert will only print an error if the results do not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip_cleaned.shape[0] + nb_missing_values) == tax_data_valid_zip.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Percentile Income per Zip Code\n",
    "\n",
    "* The function `compute_percentile_zipcode` below computes the percentile income per zip code\n",
    "\n",
    "* By default percentile=0.5,  i.e., the function computes the median\n",
    "\n",
    "* Read the code and make sure you understand what it does before moving on to the next question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_percentile_zip(df_zip, percentile=0.5):     \n",
    "    index_median = sum(( df_zip[\"N1\"]/ sum(df_zip[\"N1\"])).cumsum() <= percentile)\n",
    "    val_below_or_at_median = (df_zip[\"A00100\"] /df_zip[\"N1\"]).iloc[index_median]\n",
    "    return val_below_or_at_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the 65th income percentile ( percentile=0.65) for each zipcode in `tax_data_valid_zip_cleaned` data frame\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  \n",
    "  * Recall that you can use the `apply` function to transform the values of a column\n",
    "  \n",
    "  \n",
    "* Sort the values in descending order and assign them to a new `DataFrame` called `zip_rev_all`\n",
    "* The resulting `Series` should look like the following( '...' represents remaining data that is not shown)\n",
    "\n",
    "```Python\n",
    "ZIPCODE\n",
    "33109    3954.114286\n",
    "33480    3413.301538\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the three zip codes with the most significant 65th percentile value for income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Working with the Medicaid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring the data \n",
    "\n",
    "* Load the Medicaid data stored in the file `medicaid_data.csv` into a `DataFrame` called `medicaid_data`. The file is located in the `data` directory of the assignment folder. \n",
    "* Note that this is quite large and may take some time to load on a computer with modest RAM resources (4GB or less)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Modify `medicaid_data` to uppercase all the column names \n",
    "\n",
    "  - If your solution uses an assignment, the righthand side of the assignment (rvalue) can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Familiarize your self with the data\n",
    "  - the `NDC` column stands for National Drug Code, a universal product identifier for human drugs in the United States\n",
    "  \n",
    "  - The remaining column names are self-explanatory\n",
    "  \n",
    "- Explore the number of lines and columns in the data\n",
    "\n",
    "- Check that your column headers are in uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you explore the  `Location` column for all the entries for which \"STATE\" value is equal to \"HI\" you'll notice that all the values are identical\n",
    "\n",
    "* Are there any states that have more than one value for `Location`. \n",
    "  * Hint: think about using a sorted aggregation as part of a split-apply-combine operation to answer this question\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* To compare medication prescriptions across states in a fair and balanced way, we need the number of Medicaid beneficiaries in each state. The following example illustrates the importance of normalizing the values `UNITS REIMBURSED` for each medication in each state by the number of Medicaid enrollees in each state.\n",
    "  \n",
    "* The `medicaid_data` DataFrame shows that for the drug with NDC `61958180101` (the drug name is HARVONI and it's used to treat Hepatitis C) there were 11,886  units sold in KY, versus 40,142 in CA -- that's almost 4 times more units sold in CA compared to KY. However, there are 1,284,193 Medicaid enrollees in KY, versus 13,096,861 in California. If we normalize the number of units sold in KY, versus CA, we find that the normalized there were close to 3 times more HARVONI prescription in KY  than in CA. This is ___perhaps___ justified by the fact the KY has one of the highest rates of reported cases of Hepatitis C in the US (2.7% in KY versus 0.2% in CA).\n",
    "  \n",
    "https://www.cdc.gov/hepatitis/statistics/2015surveillance/pdfs/2015hepsurveillancerpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of enrollees per state was obtained here:\n",
    "\n",
    "    https://www.medicaid.gov/medicaid/managed-care/enrollment/index.html\n",
    "    \n",
    "    \n",
    "* A parsed/processed version (medicaid_enrollment.tsv) can be in data director of the assignment folder. Use `pandas` to load the medicaid_enrollmen file into DataFrame named `medicaid_enrollment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify `medicaid_enrollment` to uppercase all the column names \n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties\n",
    "  * Do not hardcode the operation by uppercasing the columns yourself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that some states/territories have missing values. Remove the missing values and save the resulting `DataFrame` as a new variable named `medicaid_enrollment_cleaned`\n",
    "\n",
    "* Pay attention to how 'n/a' is given here!\n",
    "* After cleaning, do you still have the Guam entry? If so, reconsider what missing values means in this context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting `TOTAL MEDICAID ENROLLEE` Data Type\n",
    "\n",
    "* Given that data on `TOTAL MEDICAID ENROLLEE` column contains commas on file (ex. 3,269,999 instead of 3269999), `pandas` has erroneously set the data type for that column as a string. We need to convert the column from string to `int` since we will be using it in an arithmetic expression during normalization\n",
    "\n",
    " \n",
    "\n",
    "* Inspect the `dtype` property of \"TOTAL MEDICAID ENROLLEES\" column, and  make sure that the data type is `int`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associating `medicaid_data` and `medicaid_enrollment_cleaned`\n",
    "\n",
    "- We can use the shared State information across both tables to associate both tables (SQL JOIN).\n",
    "- However,  `medicaid_data` contains two-letter state abbreviations, while `medicaid_enrollment_cleaned` contains the complete state name\n",
    "  - We need to convert (or append) two-letter state abbreviations to `medicaid_enrollment_cleaned`\n",
    "\n",
    "- Pandas can read HTML and parse the code for tables. We will use that functionality to read in the state abbreviations from a Wikipedia page.\n",
    "  - A brief description of what the code does is included in the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US State:</th>\n",
       "      <th>Abbreviation:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    US State: Abbreviation:\n",
       "0     Alabama            AL\n",
       "1      Alaska            AK\n",
       "2     Arizona            AZ\n",
       "3    Arkansas            AR\n",
       "4  California            CA"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reads all the tables at the given url\n",
    "# Header=0 instructs pandas to use line 0 as the header (columns)\n",
    "tables = pd.read_html('https://www.50states.com/abbreviations.htm', header=0)\n",
    "\n",
    "\n",
    "\n",
    "# We access the desired table by giving it's index.\n",
    "# Since the URL contain only one table, then we can access that table using index 0\n",
    "Codes_abbreviations = tables[0]\n",
    "Codes_abbreviations.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the the `DataFrame`'s headers from ['US State:', 'Abbreviation:'] to ['US STATE', 'ABBREVIATION']\n",
    "\n",
    "  * You can hard code this operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combine the tables `medicaid_enrollment_cleaned` and `Codes_abbreviations` such that the resulting `DataFrame` contains all the columns in `medicaid_enrollment_cleaned` and only `ABBREVIATION` from `Codes_abbreviations` \n",
    "* Save the results to variable named `medicaid_enrollment_cleaned_with_zip`\n",
    "\n",
    "- `medicaid_enrollment_cleaned_with_zip` should look like the following ( '...' represents remaining data that is not shown):\n",
    "\n",
    "\n",
    "```\n",
    "   STATE    Total Medicaid Enrollees    ABBREVIATION\n",
    "0    Alabama    1,050,989    AL\n",
    "1    Alaska    164,783    AK\n",
    "2    Arizona    1,740,520    AZ\n",
    "3    Arkansas    762,166    AR\n",
    "4    California    13,096,861    CA\n",
    "...\n",
    "```\n",
    "\n",
    "* We did not cover joins in class -- you find a plethora of examples on how to do this online. See for instance:\n",
    "\n",
    "`https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html`\n",
    "\n",
    "* If you cannot get it to work, contact the `TA` for the solution. You will not be penalized if you don't answer this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have no further use for the column STATE in  `medicaid_enrollment_cleaned_with_zip`\n",
    "  * Remove the column make sure your data in `medicaid_enrollment_cleaned_with_zip` looks like the following  ( `...` represents remaining data that is not shown):\n",
    "\n",
    "```\n",
    "    Total Medicaid Enrollees    ABBREVIATION\n",
    "0   1,050,989                  AL\n",
    "1   164,783                    AK\n",
    "2   1,740,520                  AZ\n",
    "3   762,166                    AR\n",
    "4   13,096,861                 CA\n",
    "....\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `DataFrame medicaid_enrollment_cleaned_with_zip` to assign the appropriate number of Medicaid enrollees to each entry in the `medicaid_data`\n",
    "\n",
    "   I.E., instead of the 10 original columns, `medicaid_data` will now have an 11th column representing the `TOTAL MEDICAID ENROLLEES` according to the STATE value in the entry.\n",
    "   \n",
    "- Save the resulting DataFrame into a new variable called `medicaid_data_w_enrollments`\n",
    "- The resulting DataFrame should look like the following (`...` represents remaining data that is not shown):\n",
    "\n",
    "```\n",
    "UTILIZATION TYPE    STATE    NDC    PRODUCT NAME    UNITS REIMBURSED    NUMBER OF PRESCRIPTIONS    TOTAL AMOUNT REIMBURSED    MEDICAID AMOUNT REIMBURSED    NON MEDICAID AMOUNT REIMBURSED    LOCATION\n",
    "0    MCOU    PA    55150023930    Dexamethas    33.0    19.0    234.98    234.98    0.0    (40.5773, -77.264)\n",
    "1    FFSU    NY    23917710    ALPHAGAN P    570.0    57.0    16006.34    16006.34    0.0    (42.1497, -74.9384)\n",
    "2    MCOU    OR    13925050501    Dapsone 10    456.0    15.0    1052.42    1052.42    0.0    (44.5672, -122.1269)\n",
    "...\n",
    "```\n",
    "\n",
    "* The order of the columns in the `DataFrame` is not important. This answer uses the same approach as the one used to `merge` the tables above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove any lines where \"STATE\" or \"PRODUCT NAME\" are missing from  `medicaid_data_w_enrollments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use [\"STATE\", \"PRODUCT NAME\"] as hierarchical index for `medicaid_data_w_enrollments`. Recall that a hierarchical index is simply an index with multiple levels of indexing (multiple columns)\n",
    "  * Hint: the function to set an index on a `DataFrame` can take a single column name or a list of column names. The list here is  [\"STATE\", \"NDC\"]\n",
    "- Call the new data `medicaid_data_w_enrollments_hierarch`\n",
    "- Inspect your data to make sure the new index has now two levels (STATE and NDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Write a single Pandas expression to print all the lines with containing NDC 61958180101 in \"PA\"\n",
    "\n",
    " * Use a single indexing call (bracket notation) using `loc`\n",
    " \n",
    " * Hint 1: Since your index is hierarchical, `loc` is expecting two values, the first for STATE and the second for NDC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the normalized `UNITS REIMBURSED` per druc \n",
    "\n",
    "* Compute the `UNITS REIMBURSED` for each \"NDC\" in each state normalized by the number of enrollees.\n",
    "\n",
    "- For instance in `PA`, the total `UNITS REIMBURSED` for the HARVONI `NDC` (61958180101) is 10,612\n",
    "\n",
    "```python\n",
    "total_amount_reimbursed = medicaid_data_w_enrollments_hierarch.loc[(\"PA\", 61958180101), \"UNITS REIMBURSED\"].sum() \n",
    "```\n",
    "\n",
    "- And the numebr of Medicaid Enrollees in \"PA\" is 2,569,232\n",
    "\n",
    "\n",
    "```python\n",
    "total_enrollees_PA = medicaid_data_w_enrollments_hierarch.loc[\"PA\", \"TOTAL MEDICAID ENROLLEES\"].unique()[0]\n",
    "```\n",
    "- Therefore, the UNITS REIMBURSED per enrollee  for \"HARVONI\" is  0.00413041718303\n",
    "\n",
    "\n",
    "```python\n",
    "print(total_amount_reimbursed/total_enrollees_AK)\n",
    "```\n",
    "\n",
    "- Rather than work directly with the ratios, we are going to compute and work with thier logarithm (np.log2) instead.\n",
    "\n",
    "  - The reason we use logs here is to avoid working small numbers. More on log-transformation in future lectures\n",
    "\n",
    "- Save the result in a `Series` called `medicaid_reimbursement_per_enrollee`\n",
    "\n",
    "\n",
    "- Your final result should be a Series that look like the following ( `...` represents data that is not shown here):\n",
    "  \n",
    "```\n",
    "STATE  NDC    \n",
    "AK     2143380    -9.609109\n",
    "       2143480   -10.008280\n",
    "       2322730    -6.109830\n",
    "       2322830    -4.444321\n",
    "       2322930    -3.855995\n",
    "...\n",
    "\n",
    "AL     2143380    -9.940595\n",
    "       2143480    -9.805485\n",
    "       2322730    -5.336260\n",
    "...\n",
    "\n",
    "MA     2143380    -7.921997\n",
    "       2143480    -7.803463\n",
    "       2144511   -13.472194\n",
    "       2197590    -7.741402\n",
    "       2322730    -5.414724\n",
    "       2322830    -4.592154\n",
    "       2322930    -4.205626\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To facilitate working with the final data, we are going to unstack `medicaid_reimbursement_per_enrollee` into a variable called  `medicaid_norm_ndc`\n",
    "\n",
    "- Using `medicaid_reimbursement_per_enrollee`, generate a `DataFrame` where: \n",
    "  - index should be the two-letter state symbol \n",
    "  - the column names should be the NDC codes \n",
    "\n",
    "- The `DataFrame`  should be formatted as in the image below\n",
    "  - Hint, simply unstack the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/unstacked.png\" alt=\"drawing\" style=\"width:900px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the data (very briefly) \n",
    "- What is the drug with the highest log-normalized ratio in Hawaii?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Investigate the NDC of the product with the highest log-normalized ratio in Hawaii \n",
    "  * What is it used for?\n",
    "\n",
    "* Compare the value of `Units Reimbursed` that product between HI and other states, (take for instance MA, FL, OR and WA)\n",
    "* Can you think for reasons why this product has the highest log-normalized ratio in Hawaii?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR ANSWER HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find and list all unique `NDC`s for which the difference between the largest and second large log-normalized ratio by state is at least 10.\n",
    "\n",
    "* For instance:\n",
    "  * The highest log-normalized ratio for `00591289749` (`AZACITIDIN`) is OK where it has a log-normalized ratio  of `-1.025642`.\n",
    "  * The second highest log-normalized ratio for `00591289749` is in `GA` where is has a log-normalized ration of  `-12.623428`\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Drug `AZACITIDINE` has a very high normalized UNITS REIMBURSED in OK compared to other states.\n",
    "   - Normalized log value is -1.025642 (or a ratio 0.49119167009735065)\n",
    "   - Second highest state has a log value of -12.623428 (0.000158478197834722)\n",
    "- Oklahoma is not a high-incidence state for cancer\n",
    "- Could the following explain what is happening in Oklahoma?\n",
    "\n",
    "https://www.centerwatch.com/clinical-trials/listings/92093/acute-myeloid-leukemia-aml-study-asp2215-gilteritinib-by/?&geo_lat=35.4675602&geo_lng=-97.5164276&radius=10"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}